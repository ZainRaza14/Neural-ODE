{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code is for Neural Ordinary Differential Equations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
    "        return x.view(-1, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "def norm(dim):\n",
    "    return nn.GroupNorm(min(32, dim), dim)\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this block I am implementing a residual block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the Adjoint Method (ODE Solver)\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "\n",
    "## Normal Residual Block Example\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "\n",
    "    #init a block - Convolve, pool, activate, repeat\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.norm1 = norm(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.norm2 = norm(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "\n",
    "    #Forward pass - pass output of one layer to the input of the next \n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        out = self.relu(self.norm1(x))\n",
    "        out = self.conv1(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        return out + shortcut\n",
    "\n",
    "## Ordinary Differential Equation Definition     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this cell I am Implementing Ordinary Differential Equation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEfunc(nn.Module):\n",
    "\n",
    "    # init ODE variables\n",
    "    def __init__(self, dim):\n",
    "        super(ODEfunc, self).__init__()\n",
    "        self.norm1 = norm(dim)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = conv3x3(dim, dim)\n",
    "        self.norm2 = norm(dim)\n",
    "        self.conv2 = conv3x3(dim, dim)\n",
    "        self.norm3 = norm(dim)\n",
    "        self.nfe = 0\n",
    "\n",
    "    # init ODE operations \n",
    "    def forward(self, t, x):\n",
    "      #nfe = number of function evaluations per timestep\n",
    "        self.nfe += 1\n",
    "        out = self.norm1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm3(out)\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this cell, Ordinary Differential Equation block is being implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## ODE block\n",
    "class ODEBlock(nn.Module):\n",
    "\n",
    "    #initialized as an ODE Function\n",
    "    #count the time\n",
    "    def __init__(self, odefunc):\n",
    "        super(ODEBlock, self).__init__()\n",
    "        self.odefunc = odefunc\n",
    "        self.integration_time = torch.tensor([0, 1]).float()\n",
    "\n",
    "    #foorward pass \n",
    "    #input the ODE function and input data into the ODE Solver (adjoint method)\n",
    "    # to compute a forward pass\n",
    "    def forward(self, x):\n",
    "        self.integration_time = self.integration_time.type_as(x)\n",
    "        out = odeint(self.odefunc, x, self.integration_time, rtol=args.tol, atol=args.tol)\n",
    "        return out[1]\n",
    "\n",
    "    @property\n",
    "    def nfe(self):\n",
    "        return self.odefunc.nfe\n",
    "\n",
    "    @nfe.setter\n",
    "    def nfe(self, value):\n",
    "        self.odefunc.nfe = value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main Method\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    \n",
    "    #Add Pooling\n",
    "    downsampling_layers = [\n",
    "         nn.Conv2d(1, 64, 3, 1),\n",
    "         ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\n",
    "         ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\n",
    "     ]\n",
    "\n",
    "    # Initialize the network as 1 ODE Block\n",
    "    feature_layers = [ODEBlock(ODEfunc(64))] \n",
    "    # Fully connected Layer at the end\n",
    "    fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]\n",
    "  \n",
    "    #The Model consists of an ODE Block, pooling, and a fully connected block at the end\n",
    "    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)\n",
    "\n",
    "    #Declare Gradient Descent Optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\n",
    "\n",
    "    #Training Loop\n",
    "    for itr in range(args.nepochs * batches_per_epoch):\n",
    "\n",
    "        \n",
    "        #init the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Generate training data\n",
    "        x, y = data_gen()\n",
    "        #Input Training data to model, get Prediction\n",
    "        logits = model(x)\n",
    "        #Compute Error using Prediction vs Actual Label\n",
    "        loss = CrossEntropyLoss(logits, y)\n",
    "        \n",
    "        #Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
